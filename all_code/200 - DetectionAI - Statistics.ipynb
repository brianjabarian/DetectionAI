{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON File from Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = 'generated_output_gpt-4.1-2025-04-14_all_detectors.json' # gpt 4.1\n",
    "# input_path = 'generated_output_claude-sonnet-4-20250514_all_detectors.json' # claude sonnet 4\n",
    "# input_path = 'generated_output_gemini-2.0-flash_all_detectors.json' # gemini-2.0-flash\n",
    "# input_path = 'generated_output_claude-opus-4-20250514_all_detectors.json' # claude opus 4\n",
    "\n",
    "# input_path = 'generated_output_gpt-4.1-2025-04-14_stealthgpt_all_detectors.json' # gpt 4.1 stealth\n",
    "# input_path = 'generated_output_claude-opus-4-20250514_stealthgpt_all_detectors.json' # claude opus stealth\n",
    "# input_path = 'generated_output_claude-sonnet-4-20250514_stealthgpt_all_detectors.json' # claude sonnet stealth\n",
    "# input_path = 'generated_output_gemini-2.0-flash_stealthgpt_all_detectors.json' # gemini 2.0 flash stealth\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1992 entries, 0 to 1991\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   text           1992 non-null   object\n",
      " 1   year           1992 non-null   object\n",
      " 2   genre          1992 non-null   object\n",
      " 3   source         1992 non-null   object\n",
      " 4   topic          1992 non-null   object\n",
      " 5   ai_generated   1992 non-null   object\n",
      " 6   human_verdict  1992 non-null   object\n",
      " 7   ai_verdicts    1992 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 124.6+ KB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "df = pd.DataFrame(dataset)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1747702833318,
     "user": {
      "displayName": "Ziyue Feng",
      "userId": "14163341396518175432"
     },
     "user_tz": 300
    },
    "id": "7sKYkxKNI0L4",
    "outputId": "d2b577f5-02e8-413c-f905-f36012146ff4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing thresholds for all configured detectors from file: generated_output_gemini-2.0-flash_stealthgpt_all_detectors.json\n",
      "\n",
      "--- Processing Detector: 'pengram' ---\n",
      "✅ FPR 0.01 % | Threshold: 0.37896663 (from 1992 scores)\n",
      "✅ FPR 0.50 % | Threshold: 0.00201017 (from 1992 scores)\n",
      "✅ FPR 1.00 % | Threshold: 0.00057473 (from 1992 scores)\n",
      "✅ FPR 5.00 % | Threshold: 0.00007047 (from 1992 scores)\n",
      "✅ FPR 10.00% | Threshold: 0.00002279 (from 1992 scores)\n",
      "--------------------------------------------------\n",
      "--- Processing Detector: 'originality' ---\n",
      "✅ FPR 0.01 % | Threshold: 0.99242762 (from 1322 scores)\n",
      "✅ FPR 0.50 % | Threshold: 0.05767250 (from 1322 scores)\n",
      "✅ FPR 1.00 % | Threshold: 0.02273200 (from 1322 scores)\n",
      "✅ FPR 5.00 % | Threshold: 0.00240000 (from 1322 scores)\n",
      "✅ FPR 10.00% | Threshold: 0.00090000 (from 1322 scores)\n",
      "--------------------------------------------------\n",
      "--- Processing Detector: 'gptzero' ---\n",
      "✅ FPR 0.01 % | Threshold: 1.00000000 (from 1475 scores)\n",
      "✅ FPR 0.50 % | Threshold: 1.00000000 (from 1475 scores)\n",
      "✅ FPR 1.00 % | Threshold: 0.00000000 (from 1475 scores)\n",
      "✅ FPR 5.00 % | Threshold: 0.00000000 (from 1475 scores)\n",
      "✅ FPR 10.00% | Threshold: 0.00000000 (from 1475 scores)\n",
      "--------------------------------------------------\n",
      "--- Processing Detector: 'roberta-base-detector' ---\n",
      "✅ FPR 0.01 % | Threshold: 0.99983308 (from 1992 scores)\n",
      "✅ FPR 0.50 % | Threshold: 0.99983192 (from 1992 scores)\n",
      "✅ FPR 1.00 % | Threshold: 0.99983157 (from 1992 scores)\n",
      "✅ FPR 5.00 % | Threshold: 0.99982989 (from 1992 scores)\n",
      "✅ FPR 10.00% | Threshold: 0.99982750 (from 1992 scores)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Summary of All Thresholds ---\n",
      "                       FPR_0.010%  FPR_0.500%  FPR_1.000%  FPR_5.000%  FPR_10.000%\n",
      "Detector                                                                          \n",
      "pengram                0.37896663  0.00201017  0.00057473  0.00007047   0.00002279\n",
      "originality            0.99242762  0.05767250  0.02273200  0.00240000   0.00090000\n",
      "gptzero                1.00000000  1.00000000  0.00000000  0.00000000   0.00000000\n",
      "roberta-base-detector  0.99983308  0.99983192  0.99983157  0.99982989   0.99982750\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd  # Import pandas for better table formatting\n",
    "\n",
    "def compute_threshold(data, detector_name, score_extractor, fpr_target=0.01):\n",
    "    \"\"\"\n",
    "    Computes a score threshold for a given detector based on a target \n",
    "    False Positive Rate (FPR) on human-written texts.\n",
    "    Returns the calculated threshold and the number of scores found.\n",
    "    \"\"\"\n",
    "    human_scores = []\n",
    "    for item in data:\n",
    "        human_verdict = item.get(\"human_verdict\", {})\n",
    "        detector_result = human_verdict.get(detector_name)\n",
    "\n",
    "        if detector_result:\n",
    "            score = score_extractor(detector_result)\n",
    "            if score is not None:\n",
    "                human_scores.append(score)\n",
    "\n",
    "    if not human_scores:\n",
    "        return None, 0 # Return None for threshold and 0 for count\n",
    "\n",
    "    # np.quantile is the standard and safest way to find a percentile value.\n",
    "    threshold = np.quantile(human_scores, 1 - fpr_target)\n",
    "    \n",
    "    return threshold, len(human_scores)\n",
    "\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Define the list of FPR targets you want to test\n",
    "FPR_TARGETS = [0.0001, 0.005, 0.010, 0.050, 0.100]\n",
    "\n",
    "# Define how to extract the score for each detector\n",
    "SCORE_EXTRACTORS = {\n",
    "    \"pengram\": lambda result: result.get(\"ai_likelihood\"),\n",
    "    \"originality\": lambda result: result.get(\"confidence\", {}).get(\"AI\"),\n",
    "    \"gptzero\": lambda result: result.get(\"average_generated_prob\"),\n",
    "    \"roberta-base-detector\": lambda result: result if isinstance(result, (float, int)) else None\n",
    "}\n",
    "\n",
    "# --- 2. Main Execution Logic ---\n",
    "\n",
    "try:\n",
    "    # Load the data once\n",
    "    input_path = ''\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    \n",
    "    print(f\"Computing thresholds for all configured detectors from file: {input_path}\\n\")\n",
    "    \n",
    "    # Use a nested dictionary to store results: {detector: {fpr: threshold}}\n",
    "    all_thresholds = {}\n",
    "    \n",
    "    # Outer loop for detectors\n",
    "    for name, extractor in SCORE_EXTRACTORS.items():\n",
    "        print(f\"--- Processing Detector: '{name}' ---\")\n",
    "        all_thresholds[name] = {}\n",
    "        \n",
    "        # Inner loop for each FPR target\n",
    "        for fpr in FPR_TARGETS:\n",
    "            threshold, score_count = compute_threshold(dataset, name, extractor, fpr_target=fpr)\n",
    "            \n",
    "            if threshold is not None:\n",
    "                all_thresholds[name][fpr] = threshold\n",
    "                print(f\"✅ FPR {fpr*100:<5.2f}% | Threshold: {threshold:.8f} (from {score_count} scores)\")\n",
    "            else:\n",
    "                print(f\"⚠️ No valid scores found for '{name}'. Cannot compute threshold.\")\n",
    "                # Break inner loop if no scores are found at all for this detector\n",
    "                break \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # --- 3. Final Summary Table ---\n",
    "    print(\"\\n--- Summary of All Thresholds ---\")\n",
    "    \n",
    "    # Convert the nested dictionary to a pandas DataFrame for nice printing\n",
    "    # This creates a much more readable table\n",
    "    summary_df = pd.DataFrame(all_thresholds).T # .T transposes the DataFrame\n",
    "    summary_df.index.name = \"Detector\"\n",
    "    summary_df.columns = [f\"FPR_{col*100:.3f}%\" for col in summary_df.columns]\n",
    "    \n",
    "    if not summary_df.empty:\n",
    "        print(summary_df.to_string(float_format=\"%.8f\"))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: The file was not found at the path: {input_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Label based on Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 689,
     "status": "ok",
     "timestamp": 1747703027163,
     "user": {
      "displayName": "Ziyue Feng",
      "userId": "14163341396518175432"
     },
     "user_tz": 300
    },
    "id": "tnxcHCarNyX1",
    "outputId": "e886de41-e36a-4ef2-9058-f9ed0ba9d0dd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying multi-FPR labels: 100%|██████████| 1990/1990 [00:00<00:00, 21736.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labeling completed. Output file: generated_output_claude-sonnet-4-20250514_stealthgpt_all_detectors_with_multi_fpr_labels.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# **IMPORTANT**: Populate this dictionary with the results from your previous script.\n",
    "THRESHOLDS = {\n",
    "    \"pengram\": {\n",
    "        0.0001: 0.37923204,\n",
    "        0.005:  0.00201159,\n",
    "        0.010:  0.00057646,\n",
    "        0.050:  0.00007047,\n",
    "        0.100:  0.00002258\n",
    "    },\n",
    "    \"originality\": {\n",
    "        0.0001: 0.99253326,\n",
    "        0.005:  0.05871750,\n",
    "        0.010:  0.02301900,\n",
    "        0.050:  0.00250000,\n",
    "        0.100:  0.00100000\n",
    "    },\n",
    "    \"gptzero\": {\n",
    "        0.0001: 1.00000000 ,\n",
    "        0.005:  1.00000000 ,\n",
    "        0.010:  0.00000000,\n",
    "        0.050:  0.00000000,\n",
    "        0.100:  0.00000000\n",
    "    },\n",
    "    \"roberta-base-detector\": {\n",
    "        0.0001: 0.99983308 ,\n",
    "        0.005:  0.99983192 ,\n",
    "        0.010:  0.99983157,\n",
    "        0.050:  0.99982989,\n",
    "        0.100:  0.99982750\n",
    "    }\n",
    "}\n",
    "\n",
    "# THRESHOLDS = {\n",
    "#     \"pengram\": {\n",
    "#         0.99: 0.99,\n",
    "#         0.97: 0.97,\n",
    "#         0.95: 0.95,\n",
    "#         0.90: 0.90,\n",
    "#         0.80: 0.80\n",
    "#     },\n",
    "#     \"originality\": {\n",
    "#         0.99: 0.99,\n",
    "#         0.97: 0.97,\n",
    "#         0.95: 0.95,\n",
    "#         0.90: 0.90,\n",
    "#         0.80: 0.80\n",
    "#     },\n",
    "#     \"gptzero\": {\n",
    "#         0.99: 0.99,\n",
    "#         0.97: 0.97,\n",
    "#         0.95: 0.95,\n",
    "#         0.90: 0.90,\n",
    "#         0.80: 0.80\n",
    "#     },\n",
    "#     \"roberta-base-detector\": {\n",
    "#         0.99: 0.99,\n",
    "#         0.97: 0.97,\n",
    "#         0.95: 0.95,\n",
    "#         0.90: 0.90,\n",
    "#         0.80: 0.80\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# This tells the script how to find the score for each detector. (Unchanged)\n",
    "SCORE_EXTRACTORS = {\n",
    "    \"pengram\": lambda result: result.get(\"ai_likelihood\"),\n",
    "    \"originality\": lambda result: result.get(\"confidence\", {}).get(\"AI\"),\n",
    "    \"gptzero\": lambda result: result.get(\"average_generated_prob\"),\n",
    "    \"roberta-base-detector\": lambda result: result if isinstance(result, (float, int)) else None\n",
    "}\n",
    "\n",
    "# --- 2. File Paths ---\n",
    "input_file = ''  # ← Your input file\n",
    "output_file = '' # \n",
    "\n",
    "# --- 3. Main Labeling Logic ---\n",
    "\n",
    "def get_label(detector_result, score_extractor, threshold):\n",
    "    \"\"\"Safely extracts a score, compares it to a threshold, and returns a label.\"\"\"\n",
    "    if not detector_result:\n",
    "        return None\n",
    "    score = score_extractor(detector_result)\n",
    "    if score is None:\n",
    "        return None\n",
    "    return 1 if score > threshold else 0\n",
    "\n",
    "\n",
    "# Load the JSON data\n",
    "try:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: The file was not found at the path: {input_file}\")\n",
    "    exit()\n",
    "\n",
    "# Loop through each entry in the dataset to add labels\n",
    "for entry in tqdm(data, desc=\"Applying multi-FPR labels\"):\n",
    "    \n",
    "    # Initialize new dictionaries to hold the nested labels for this entry\n",
    "    entry[\"human_labels_by_fpr\"] = {}\n",
    "    entry[\"ai_labels_by_fpr\"] = {}\n",
    "\n",
    "    # --- Process Human Verdict for all detectors and FPRs ---\n",
    "    human_verdict = entry.get(\"human_verdict\", {})\n",
    "    for detector_name, fpr_thresholds in THRESHOLDS.items():\n",
    "        entry[\"human_labels_by_fpr\"][detector_name] = {}\n",
    "        detector_result = human_verdict.get(detector_name)\n",
    "        score_extractor = SCORE_EXTRACTORS[detector_name]\n",
    "        \n",
    "        for fpr, threshold in fpr_thresholds.items():\n",
    "            label = get_label(detector_result, score_extractor, threshold)\n",
    "            fpr_key = f\"FPR_{fpr*100:.3f}%\"\n",
    "            entry[\"human_labels_by_fpr\"][detector_name][fpr_key] = label\n",
    "\n",
    "    # --- Process all AI Verdicts for all detectors and FPRs ---\n",
    "    ai_verdicts_by_model = entry.get(\"ai_verdicts\", {})\n",
    "    for model_name, model_verdicts in ai_verdicts_by_model.items():\n",
    "        entry[\"ai_labels_by_fpr\"][model_name] = {}\n",
    "        for detector_name, fpr_thresholds in THRESHOLDS.items():\n",
    "            entry[\"ai_labels_by_fpr\"][model_name][detector_name] = {}\n",
    "            detector_result = model_verdicts.get(detector_name)\n",
    "            score_extractor = SCORE_EXTRACTORS[detector_name]\n",
    "            \n",
    "            for fpr, threshold in fpr_thresholds.items():\n",
    "                label = get_label(detector_result, score_extractor, threshold)\n",
    "                fpr_key = f\"FPR_{fpr*100:.3f}%\"\n",
    "                entry[\"ai_labels_by_fpr\"][model_name][detector_name][fpr_key] = label\n",
    "\n",
    "# Save the results to the new output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Labeling completed. Output file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "input_path = 'generated_output_gemini-2.0-flash_stealthgpt_all_detectors_with_multi_fpr_labels.json'\n",
    "with open(input_path, 'r') as f:\n",
    "    check = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>ai_generated</th>\n",
       "      <th>stealthgpt_rephrased</th>\n",
       "      <th>human_verdict</th>\n",
       "      <th>ai_verdicts</th>\n",
       "      <th>human_labels_by_fpr</th>\n",
       "      <th>ai_labels_by_fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The proposed training, which would have been provided by volunteers at no cost to the state, would occur during orientation for legislators at the beginning of each session.The bill was not prompt...</td>\n",
       "      <td>2014</td>\n",
       "      <td>news</td>\n",
       "      <td>https://huggingface.co/datasets/cc_news</td>\n",
       "      <td>North Dakota Senate rejects cultural competency training bill for legislators, opting for a study instead, following concerns about overreach and strained relationships post-Dakota Access Pipeline...</td>\n",
       "      <td>{'gemini-2.0-flash': 'The North Dakota Senate chamber buzzed with restrained energy as the vote tally flashed across the screen. A bill mandating cultural competency training for state legislators...</td>\n",
       "      <td>{'gemini-2.0-flash': 'The Senate chamber in North Dakota buzzed with contained energy when the vote tally appeared onscreen. A bill requiring cultural competency training for state legislators had...</td>\n",
       "      <td>{'pengram': {'ai_likelihood': 5.960464477539062e-07, 'prediction': 'Unlikely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0028, 'Original': 0.9971}}, 'g...</td>\n",
       "      <td>{'gemini-2.0-flash': {'pengram': {'ai_likelihood': 1.0, 'prediction': 'Highly Likely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0714, 'Original': 0.92...</td>\n",
       "      <td>{'pengram': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%': 0}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 1, 'FPR_10.000%...</td>\n",
       "      <td>{'gemini-2.0-flash': {'pengram': {'FPR_0.010%': 1, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.000%': 1, 'FPR_10.000%': 1}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TPR broke the story that Hulu and its 500 jobs would come to San Antonio pending incentives that city, county and state officials have promised.While the state of Texas has already offered nearly ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>news</td>\n",
       "      <td>https://huggingface.co/datasets/cc_news</td>\n",
       "      <td>Hulu's potential expansion to San Antonio. City and county incentives, including tax rebates, pending votes. 500 jobs expected with wage and investment requirements.</td>\n",
       "      <td>{'gemini-2.0-flash': 'San Antonio could soon be home to a major new player in the streaming world. Hulu is considering expanding its operations to the Alamo City, a move that could bring a signifi...</td>\n",
       "      <td>{'gemini-2.0-flash': 'A new, major player in the streaming world could soon be calling San Antonio home. Hulu is looking at expanding its operations to the River City, which could provide a shot i...</td>\n",
       "      <td>{'pengram': {'ai_likelihood': 0.0, 'prediction': 'Unlikely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0003, 'Original': 0.9995}}, 'gptzero': {'average...</td>\n",
       "      <td>{'gemini-2.0-flash': {'pengram': {'ai_likelihood': 1.0, 'prediction': 'Highly Likely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0101, 'Original': 0.98...</td>\n",
       "      <td>{'pengram': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%': 0}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%...</td>\n",
       "      <td>{'gemini-2.0-flash': {'pengram': {'FPR_0.010%': 1, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.000%': 1, 'FPR_10.000%': 1}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  The proposed training, which would have been provided by volunteers at no cost to the state, would occur during orientation for legislators at the beginning of each session.The bill was not prompt...   \n",
       "1  TPR broke the story that Hulu and its 500 jobs would come to San Antonio pending incentives that city, county and state officials have promised.While the state of Texas has already offered nearly ...   \n",
       "\n",
       "   year genre                                   source  \\\n",
       "0  2014  news  https://huggingface.co/datasets/cc_news   \n",
       "1  2017  news  https://huggingface.co/datasets/cc_news   \n",
       "\n",
       "                                                                                                                                                                                                     topic  \\\n",
       "0  North Dakota Senate rejects cultural competency training bill for legislators, opting for a study instead, following concerns about overreach and strained relationships post-Dakota Access Pipeline...   \n",
       "1                                    Hulu's potential expansion to San Antonio. City and county incentives, including tax rebates, pending votes. 500 jobs expected with wage and investment requirements.   \n",
       "\n",
       "                                                                                                                                                                                              ai_generated  \\\n",
       "0  {'gemini-2.0-flash': 'The North Dakota Senate chamber buzzed with restrained energy as the vote tally flashed across the screen. A bill mandating cultural competency training for state legislators...   \n",
       "1  {'gemini-2.0-flash': 'San Antonio could soon be home to a major new player in the streaming world. Hulu is considering expanding its operations to the Alamo City, a move that could bring a signifi...   \n",
       "\n",
       "                                                                                                                                                                                      stealthgpt_rephrased  \\\n",
       "0  {'gemini-2.0-flash': 'The Senate chamber in North Dakota buzzed with contained energy when the vote tally appeared onscreen. A bill requiring cultural competency training for state legislators had...   \n",
       "1  {'gemini-2.0-flash': 'A new, major player in the streaming world could soon be calling San Antonio home. Hulu is looking at expanding its operations to the River City, which could provide a shot i...   \n",
       "\n",
       "                                                                                                                                                                                             human_verdict  \\\n",
       "0  {'pengram': {'ai_likelihood': 5.960464477539062e-07, 'prediction': 'Unlikely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0028, 'Original': 0.9971}}, 'g...   \n",
       "1  {'pengram': {'ai_likelihood': 0.0, 'prediction': 'Unlikely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0003, 'Original': 0.9995}}, 'gptzero': {'average...   \n",
       "\n",
       "                                                                                                                                                                                               ai_verdicts  \\\n",
       "0  {'gemini-2.0-flash': {'pengram': {'ai_likelihood': 1.0, 'prediction': 'Highly Likely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0714, 'Original': 0.92...   \n",
       "1  {'gemini-2.0-flash': {'pengram': {'ai_likelihood': 1.0, 'prediction': 'Highly Likely AI'}, 'originality': {'classification': {'AI': 0, 'Original': 1}, 'confidence': {'AI': 0.0101, 'Original': 0.98...   \n",
       "\n",
       "                                                                                                                                                                                       human_labels_by_fpr  \\\n",
       "0  {'pengram': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%': 0}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 1, 'FPR_10.000%...   \n",
       "1  {'pengram': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%': 0}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.000%': 0, 'FPR_10.000%...   \n",
       "\n",
       "                                                                                                                                                                                          ai_labels_by_fpr  \n",
       "0  {'gemini-2.0-flash': {'pengram': {'FPR_0.010%': 1, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.000%': 1, 'FPR_10.000%': 1}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.0...  \n",
       "1  {'gemini-2.0-flash': {'pengram': {'FPR_0.010%': 1, 'FPR_0.500%': 1, 'FPR_1.000%': 1, 'FPR_5.000%': 1, 'FPR_10.000%': 1}, 'originality': {'FPR_0.010%': 0, 'FPR_0.500%': 0, 'FPR_1.000%': 0, 'FPR_5.0...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "test = pd.DataFrame(check)\n",
    "test.head(2)\n",
    "# error_rows = test[test['ai_verdicts'].apply(lambda x: 'error' in str(x).lower())]\n",
    "\n",
    "# error_rows.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Precision, Recall, FPR, and FNR by Models and Detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- No word count filter applied. Processing all entries. ---\n",
      "\n",
      "--- Error Rate Analysis (Type I & II Errors) ---\n",
      "             Detector FPR Target               Error Type  Error Rate  Count  Total\n",
      "              gptzero     0.0001  Type I (False Positive)    0.000000      0   1475\n",
      "              gptzero     0.0001 Type II (False Negative)    1.000000   1475   1475\n",
      "              gptzero     0.0050  Type I (False Positive)    0.000000      0   1475\n",
      "              gptzero     0.0050 Type II (False Negative)    1.000000   1475   1475\n",
      "              gptzero     0.0100  Type I (False Positive)    0.006102      9   1475\n",
      "              gptzero     0.0100 Type II (False Negative)    0.444068    655   1475\n",
      "              gptzero     0.0500  Type I (False Positive)    0.006102      9   1475\n",
      "              gptzero     0.0500 Type II (False Negative)    0.444068    655   1475\n",
      "              gptzero     0.1000  Type I (False Positive)    0.006102      9   1475\n",
      "              gptzero     0.1000 Type II (False Negative)    0.444068    655   1475\n",
      "          originality     0.0001  Type I (False Positive)    0.000756      1   1322\n",
      "          originality     0.0001 Type II (False Negative)    0.913545   1268   1388\n",
      "          originality     0.0050  Type I (False Positive)    0.005295      7   1322\n",
      "          originality     0.0050 Type II (False Negative)    0.738473   1025   1388\n",
      "          originality     0.0100  Type I (False Positive)    0.010590     14   1322\n",
      "          originality     0.0100 Type II (False Negative)    0.656340    911   1388\n",
      "          originality     0.0500  Type I (False Positive)    0.049924     66   1322\n",
      "          originality     0.0500 Type II (False Negative)    0.185159    257   1388\n",
      "          originality     0.1000  Type I (False Positive)    0.099849    132   1322\n",
      "          originality     0.1000 Type II (False Negative)    0.049712     69   1388\n",
      "              pengram     0.0001  Type I (False Positive)    0.000502      1   1992\n",
      "              pengram     0.0001 Type II (False Negative)    0.063253    126   1992\n",
      "              pengram     0.0050  Type I (False Positive)    0.005020     10   1992\n",
      "              pengram     0.0050 Type II (False Negative)    0.028112     56   1992\n",
      "              pengram     0.0100  Type I (False Positive)    0.010040     20   1992\n",
      "              pengram     0.0100 Type II (False Negative)    0.022590     45   1992\n",
      "              pengram     0.0500  Type I (False Positive)    0.049699     99   1992\n",
      "              pengram     0.0500 Type II (False Negative)    0.010542     21   1992\n",
      "              pengram     0.1000  Type I (False Positive)    0.100402    200   1992\n",
      "              pengram     0.1000 Type II (False Negative)    0.004518      9   1992\n",
      "roberta-base-detector     0.0001  Type I (False Positive)    0.000502      1   1992\n",
      "roberta-base-detector     0.0001 Type II (False Negative)    1.000000   1992   1992\n",
      "roberta-base-detector     0.0050  Type I (False Positive)    0.005020     10   1992\n",
      "roberta-base-detector     0.0050 Type II (False Negative)    0.998996   1990   1992\n",
      "roberta-base-detector     0.0100  Type I (False Positive)    0.010040     20   1992\n",
      "roberta-base-detector     0.0100 Type II (False Negative)    0.996988   1986   1992\n",
      "roberta-base-detector     0.0500  Type I (False Positive)    0.049699     99   1992\n",
      "roberta-base-detector     0.0500 Type II (False Negative)    0.968876   1930   1992\n",
      "roberta-base-detector     0.1000  Type I (False Positive)    0.102410    204   1992\n",
      "roberta-base-detector     0.1000 Type II (False Negative)    0.894076   1781   1992\n",
      "\n",
      "\n",
      "--- Performance Metrics Analysis (Precision & Recall) ---\n",
      "             Detector FPR Target  Precision   Recall\n",
      "              gptzero     0.0001        NaN 0.000000\n",
      "              gptzero     0.0050        NaN 0.000000\n",
      "              gptzero     0.0100   0.989144 0.555932\n",
      "              gptzero     0.0500   0.989144 0.555932\n",
      "              gptzero     0.1000   0.989144 0.555932\n",
      "          originality     0.0001   0.991736 0.086455\n",
      "          originality     0.0050   0.981081 0.261527\n",
      "          originality     0.0100   0.971487 0.343660\n",
      "          originality     0.0500   0.944862 0.814841\n",
      "          originality     0.1000   0.909028 0.950288\n",
      "              pengram     0.0001   0.999464 0.936747\n",
      "              pengram     0.0050   0.994861 0.971888\n",
      "              pengram     0.0100   0.989832 0.977410\n",
      "              pengram     0.0500   0.952174 0.989458\n",
      "              pengram     0.1000   0.908383 0.995482\n",
      "roberta-base-detector     0.0001   0.000000 0.000000\n",
      "roberta-base-detector     0.0050   0.166667 0.001004\n",
      "roberta-base-detector     0.0100   0.230769 0.003012\n",
      "roberta-base-detector     0.0500   0.385093 0.031124\n",
      "roberta-base-detector     0.1000   0.508434 0.105924\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "\n",
    "# Set to True to filter by word count, or False to process the entire file.\n",
    "APPLY_WORD_COUNT_FILTER = False \n",
    "\n",
    "# Define the filtering criteria (only used if the filter is active)\n",
    "# You can choose to keep texts WITH MORE than (>=) or LESS than (<) the threshold.\n",
    "WORD_COUNT_THRESHOLD = 50\n",
    "FILTER_MODE = \"<\" # Options: \">=\" to keep long texts, \"<\" to keep short texts.\n",
    "\n",
    "# Define the exact FPR targets you used in the previous labeling script.\n",
    "FPR_TARGETS = [0.0001, 0.005, 0.010, 0.050, 0.100]\n",
    "# FPR_TARGETS = [0.99, 0.97, 0.95, 0.90, 0.80]\n",
    "\n",
    "# --- 2. Load and Optionally Filter Data ---\n",
    "input_path = \"\"\n",
    "\n",
    "try:\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: The file was not found at the path: {input_path}\")\n",
    "    exit()\n",
    "\n",
    "# By default, we process the whole dataset\n",
    "data_to_process = data.copy()\n",
    "\n",
    "# Conditionally apply the filter if the switch is on\n",
    "if APPLY_WORD_COUNT_FILTER:\n",
    "    print(f\"--- Applying Word Count Filter (Mode: {FILTER_MODE} {WORD_COUNT_THRESHOLD} words) ---\")\n",
    "    original_count = len(data)\n",
    "    \n",
    "    if FILTER_MODE == \">=\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) >= WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\">= {WORD_COUNT_THRESHOLD}\"\n",
    "    elif FILTER_MODE == \"<\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) < WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\"< {WORD_COUNT_THRESHOLD}\"\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Invalid FILTER_MODE '{FILTER_MODE}'. No filtering will be applied.\")\n",
    "        filter_desc = \"None\"\n",
    "\n",
    "    filtered_count = len(data_to_process)\n",
    "    print(f\"Filtering complete. Kept {filtered_count} of {original_count} entries (texts with {filter_desc} words).\")\n",
    "else:\n",
    "    print(\"--- No word count filter applied. Processing all entries. ---\")\n",
    "\n",
    "\n",
    "# --- 3. Build Records from the Nested Label Structure ---\n",
    "records = []\n",
    "# Check the data we intend to process\n",
    "if data_to_process:\n",
    "    detectors_in_file = list(data_to_process[0].get(\"human_labels_by_fpr\", {}).keys())\n",
    "else:\n",
    "    detectors_in_file = []\n",
    "    print(\"⚠️ No data left to process after filtering. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# *** The main loop now iterates over data_to_process ***\n",
    "for item in data_to_process:\n",
    "    for detector in detectors_in_file:\n",
    "        for fpr in FPR_TARGETS:\n",
    "            fpr_key = f\"FPR_{fpr*100:.3f}%\" # Recreate the key used in the previous script\n",
    "\n",
    "            # Process human-written text labels for each FPR\n",
    "            human_labels_by_detector = item.get(\"human_labels_by_fpr\", {}).get(detector, {})\n",
    "            if fpr_key in human_labels_by_detector and human_labels_by_detector[fpr_key] is not None:\n",
    "                records.append({\n",
    "                    \"detector\": detector,\n",
    "                    \"fpr_target\": fpr,\n",
    "                    \"is_human\": True,\n",
    "                    \"verdict\": human_labels_by_detector[fpr_key]\n",
    "                })\n",
    "\n",
    "            # Process AI-generated text labels for all models and each FPR\n",
    "            ai_labels_by_model = item.get(\"ai_labels_by_fpr\", {})\n",
    "            for model_name, model_labels in ai_labels_by_model.items():\n",
    "                ai_labels_by_detector = model_labels.get(detector, {})\n",
    "                if fpr_key in ai_labels_by_detector and ai_labels_by_detector[fpr_key] is not None:\n",
    "                    records.append({\n",
    "                        \"detector\": detector,\n",
    "                        \"fpr_target\": fpr,\n",
    "                        \"is_human\": False,\n",
    "                        \"verdict\": ai_labels_by_detector[fpr_key]\n",
    "                    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# --- 4. Wilson Score Confidence Interval Function (Unchanged) ---\n",
    "def wilson_ci(k, n, alpha=0.05):\n",
    "    if n == 0: return (0, 0)\n",
    "    z = st.norm.ppf(1 - alpha / 2)\n",
    "    phat = k / n\n",
    "    denom = 1 + z**2 / n\n",
    "    center = phat + z**2 / (2 * n)\n",
    "    pm = z * ((phat * (1 - phat) / n + z**2 / (4 * n**2)) ** 0.5)\n",
    "    return ((center - pm) / denom, (center + pm) / denom)\n",
    "\n",
    "# --- 5. Evaluation (Grouped by Detector and FPR Target) ---\n",
    "results = []\n",
    "metrics_results = []\n",
    "\n",
    "if not df.empty:\n",
    "    for (detector, fpr), group in df.groupby([\"detector\", \"fpr_target\"]):\n",
    "        human = group[group[\"is_human\"]]\n",
    "        ai = group[~group[\"is_human\"]]\n",
    "\n",
    "        total_human = len(human)\n",
    "        total_ai = len(ai)\n",
    "\n",
    "        fp = (human[\"verdict\"] == 1).sum()\n",
    "        fn = (ai[\"verdict\"] == 0).sum()\n",
    "        tp = (ai[\"verdict\"] == 1).sum()\n",
    "\n",
    "        type1_rate = fp / total_human if total_human else np.nan\n",
    "        type2_rate = fn / total_ai if total_ai else np.nan\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"Detector\": detector,\n",
    "            \"FPR Target\": f\"{fpr:.4f}\",\n",
    "            \"Error Type\": \"Type I (False Positive)\",\n",
    "            \"Error Rate\": type1_rate, \n",
    "            \"Count\": fp, \n",
    "            \"Total\": total_human\n",
    "        })\n",
    "        results.append({\n",
    "            \"Detector\": detector,\n",
    "            \"FPR Target\": f\"{fpr:.4f}\",\n",
    "            \"Error Type\": \"Type II (False Negative)\",\n",
    "            \"Error Rate\": type2_rate, \n",
    "            \"Count\": fn, \n",
    "            \"Total\": total_ai\n",
    "        })\n",
    "        metrics_results.append({\n",
    "            \"Detector\": detector,\n",
    "            \"FPR Target\": f\"{fpr:.4f}\",\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall})\n",
    "\n",
    "# --- 6. Create and Display Final DataFrames ---\n",
    "error_rates_df = pd.DataFrame(results).sort_values(by=[\"Detector\", \"FPR Target\"])\n",
    "metrics_df = pd.DataFrame(metrics_results).sort_values(by=[\"Detector\", \"FPR Target\"])\n",
    "\n",
    "print(\"\\n--- Error Rate Analysis (Type I & II Errors) ---\")\n",
    "if error_rates_df.empty:\n",
    "    print(\"No data to display.\")\n",
    "else:\n",
    "    print(error_rates_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n--- Performance Metrics Analysis (Precision & Recall) ---\")\n",
    "if metrics_df.empty:\n",
    "    print(\"No data to display.\")\n",
    "else:\n",
    "    print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_rates_df['model'] = \"GPT-4.1\"\n",
    "error_rates_df_gpt_4_1 = error_rates_df.copy()\n",
    "# error_rates_df_gpt_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_rates_df['model'] = \"Claude Opus 4\"\n",
    "error_rates_df_claude_opus_4 = error_rates_df.copy()\n",
    "# error_rates_df_claude_opus_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_rates_df['model'] = \"Claude Sonnet 4\"\n",
    "error_rates_df_claude_sonnet_4 = error_rates_df.copy()\n",
    "# error_rates_df_claude_sonnet_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_rates_df['model'] = \"Gemini 2.0 Flash\"\n",
    "error_rates_df_gemini_2_flash = error_rates_df.copy()\n",
    "# error_rates_df_gemini_2_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 160 entries, 0 to 39\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Detector    160 non-null    object \n",
      " 1   FPR Target  160 non-null    object \n",
      " 2   Error Type  160 non-null    object \n",
      " 3   Error Rate  160 non-null    float64\n",
      " 4   Count       160 non-null    int64  \n",
      " 5   Total       160 non-null    int64  \n",
      " 6   model       160 non-null    object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "error_rates_stealth_df_final = pd.concat([error_rates_df_gpt_4_1, \n",
    "                              error_rates_df_claude_opus_4,\n",
    "                              error_rates_df_claude_sonnet_4,\n",
    "                              error_rates_df_gemini_2_flash], \n",
    "                             axis = 0)\n",
    "\n",
    "error_rates_stealth_df_final.info()\n",
    "error_rates_stealth_df_final.to_csv(\"error_rates_stealth_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df['model'] = \"GPT-4.1\"\n",
    "metrics_df_gpt_4_1 = metrics_df.copy()\n",
    "# metrics_df_gpt_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df['model'] = \"Claude Opus 4\"\n",
    "metrics_df_claude_opus_4 = metrics_df.copy()\n",
    "# metrics_df_claude_opus_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df['model'] = \"Claude Sonnet 4\"\n",
    "metrics_df_claude_sonnet_4 = metrics_df.copy()\n",
    "# metrics_df_claude_sonnet_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df['model'] = \"Gemini 2.0 Flash\"\n",
    "metrics_df_gemini_2_flash = metrics_df.copy()\n",
    "# metrics_df_gemini_2_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Detector    80 non-null     object \n",
      " 1   FPR Target  80 non-null     object \n",
      " 2   Precision   72 non-null     float64\n",
      " 3   Recall      80 non-null     float64\n",
      " 4   model       80 non-null     object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 3.8+ KB\n"
     ]
    }
   ],
   "source": [
    "metrics_stealth_df_final = pd.concat([metrics_df_gpt_4_1, \n",
    "                              metrics_df_claude_opus_4,\n",
    "                              metrics_df_claude_sonnet_4,\n",
    "                              metrics_df_gemini_2_flash], \n",
    "                             axis = 0)\n",
    "\n",
    "metrics_stealth_df_final.info()\n",
    "metrics_stealth_df_final.to_csv(\"metrics_stealth_df_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AUC ROC, FPR, FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- No word count filter applied. Processing all entries. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.5311</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>0.1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5289</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                detector   AUROC  Δ-Mean     FPR     FNR  Optimal Threshold\n",
       "1                pengram  0.9981  0.9328  0.0090  0.0231             0.0008\n",
       "0            originality  0.9674  0.1862  0.0998  0.0497             0.0010\n",
       "2                gptzero  0.7748  0.5311  0.0061  0.4441             0.1176\n",
       "3  roberta-base-detector  0.5289  0.0074  0.3800  0.5472             0.9998"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 1A – AUROC, Δ-Mean, FPR & FNR\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve # Import roc_curve\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Set to True to filter by word count, or False to process the entire file.\n",
    "APPLY_WORD_COUNT_FILTER = False \n",
    "\n",
    "# Define the filtering criteria (only used if the filter is active)\n",
    "# You can choose to keep texts WITH MORE than (>=) or LESS than (<) the threshold.\n",
    "WORD_COUNT_THRESHOLD = 50\n",
    "FILTER_MODE = \"<\" # Options: \">=\" to keep long texts, \"<\" to keep short texts.\n",
    "\n",
    "# === Load JSON file ===\n",
    "# Using the file path from your last script for context\n",
    "input_path = ''\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# By default, we process the whole dataset\n",
    "data_to_process = data.copy()\n",
    "\n",
    "# Conditionally apply the filter if the switch is on\n",
    "if APPLY_WORD_COUNT_FILTER:\n",
    "    print(f\"--- Applying Word Count Filter (Mode: {FILTER_MODE} {WORD_COUNT_THRESHOLD} words) ---\")\n",
    "    original_count = len(data)\n",
    "    \n",
    "    if FILTER_MODE == \">=\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) >= WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\">= {WORD_COUNT_THRESHOLD}\"\n",
    "    elif FILTER_MODE == \"<\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) < WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\"< {WORD_COUNT_THRESHOLD}\"\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Invalid FILTER_MODE '{FILTER_MODE}'. No filtering will be applied.\")\n",
    "        filter_desc = \"None\"\n",
    "\n",
    "    filtered_count = len(data_to_process)\n",
    "    print(f\"Filtering complete. Kept {filtered_count} of {original_count} entries (texts with {filter_desc} words).\")\n",
    "else:\n",
    "    print(\"--- No word count filter applied. Processing all entries. ---\")\n",
    "\n",
    "# === Supported detectors and their probability fields ===\n",
    "detectors = {\n",
    "    \"originality\": lambda d: d.get(\"confidence\", {}).get(\"AI\", None),\n",
    "    \"pengram\": lambda d: d.get(\"ai_likelihood\", None),\n",
    "    \"gptzero\": lambda d: d.get(\"average_generated_prob\", None),\n",
    "    \"roberta-base-detector\": lambda d: d if isinstance(d, (float, int)) else None\n",
    "}\n",
    "\n",
    "# === Collect scores ===\n",
    "records = []\n",
    "for entry in data_to_process:\n",
    "    # Human text\n",
    "    hv = entry.get(\"human_verdict\", {})\n",
    "    for det, extract in detectors.items():\n",
    "        if det in hv:\n",
    "            prob = extract(hv[det])\n",
    "            if prob is not None:\n",
    "                records.append({\n",
    "                    \"detector\": det, \"source\": \"human\", \"score\": prob, \"label\": 0\n",
    "                })\n",
    "\n",
    "    # AI-generated text from all models\n",
    "    for model, verdicts in entry.get(\"ai_verdicts\", {}).items():\n",
    "        for det, extract in detectors.items():\n",
    "            if det in verdicts:\n",
    "                prob = extract(verdicts[det])\n",
    "                if prob is not None:\n",
    "                    records.append({\n",
    "                        \"detector\": det, \"source\": f\"ai_{model}\", \"score\": prob, \"label\": 1\n",
    "                    })\n",
    "\n",
    "# === Convert to DataFrame ===\n",
    "df = pd.DataFrame(records)\n",
    "if df.empty:\n",
    "    print(\"⚠️ No records were created. Please check your input JSON structure and detectors.\")\n",
    "    exit()\n",
    "\n",
    "# === Compute AUROC, Δ-Mean, FPR & FNR for each detector ===\n",
    "summary = []\n",
    "\n",
    "for det in df[\"detector\"].unique():\n",
    "    sub = df[df[\"detector\"] == det]\n",
    "    \n",
    "    # Ensure there are both human and AI scores to process\n",
    "    if not (0 in sub[\"label\"].values and 1 in sub[\"label\"].values):\n",
    "        print(f\"Skipping detector '{det}' as it's missing either human or AI scores.\")\n",
    "        continue\n",
    "\n",
    "    ai_scores = sub[sub[\"label\"] == 1][\"score\"]\n",
    "    human_scores = sub[sub[\"label\"] == 0][\"score\"]\n",
    "    all_labels = sub[\"label\"]\n",
    "    all_scores = sub[\"score\"]\n",
    "\n",
    "    # --- Calculate AUROC and Δ-Mean (your original code) ---\n",
    "    try:\n",
    "        auroc = roc_auc_score(all_labels, all_scores)\n",
    "    except ValueError:\n",
    "        auroc = None\n",
    "\n",
    "    delta_mean = ai_scores.mean() - human_scores.mean()\n",
    "\n",
    "    # --- NEW: Calculate FPR and FNR at an optimal threshold ---\n",
    "    fpr_values, tpr_values, thresholds = roc_curve(all_labels, all_scores)\n",
    "\n",
    "    # Find the optimal threshold using Youden's J statistic\n",
    "    j_statistic = tpr_values - fpr_values\n",
    "    optimal_idx = np.argmax(j_statistic)\n",
    "    \n",
    "    # Get the values at that optimal point\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_fpr = fpr_values[optimal_idx] # This is the False Positive Rate\n",
    "    optimal_tpr = tpr_values[optimal_idx] # This is the True Positive Rate (Sensitivity/Recall)\n",
    "    optimal_fnr = 1 - optimal_tpr        # False Negative Rate = 1 - TPR\n",
    "\n",
    "    summary.append({\n",
    "        \"detector\": det,\n",
    "        \"AUROC\": round(auroc, 4) if auroc is not None else \"N/A\",\n",
    "        \"Δ-Mean\": round(delta_mean, 4),\n",
    "        \"FPR\": round(optimal_fpr, 4), # Add FPR to the summary\n",
    "        \"FNR\": round(optimal_fnr, 4), # Add FNR to the summary\n",
    "        \"Optimal Threshold\": round(optimal_threshold, 4) # Also useful to see the threshold\n",
    "    })\n",
    "\n",
    "# === Final Table 1A Output ===\n",
    "summary_df = pd.DataFrame(summary)\n",
    "if not summary_df.empty:\n",
    "    summary_df = summary_df.sort_values(by=\"AUROC\", ascending=False)\n",
    "\n",
    "# print(summary_df.to_string(index=False))\n",
    "# summary_df.to_csv(\"path/to/your/output.csv\", index=False)\n",
    "\n",
    "# Display the final DataFrame\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>GPT-4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>GPT-4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.5291</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>GPT-4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>GPT-4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                detector   AUROC  Δ-Mean     FPR     FNR  Optimal Threshold  \\\n",
       "1                pengram  0.9984  0.9420  0.0090  0.0181             0.0007   \n",
       "0            originality  0.9631  0.1709  0.1078  0.0430             0.0009   \n",
       "2                gptzero  0.7322  0.4483  0.0061  0.5291             0.2407   \n",
       "3  roberta-base-detector  0.5035 -0.0095  0.3825  0.5823             0.9998   \n",
       "\n",
       "     model  \n",
       "1  GPT-4.1  \n",
       "0  GPT-4.1  \n",
       "2  GPT-4.1  \n",
       "3  GPT-4.1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['model'] = \"GPT-4.1\"\n",
    "summary_df_4_1 = summary_df.copy()\n",
    "summary_df_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Claude Opus 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Claude Opus 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.6662</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>Claude Opus 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.5035</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>Claude Opus 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                detector   AUROC  Δ-Mean     FPR     FNR  Optimal Threshold  \\\n",
       "1                pengram  0.9984  0.9253  0.0090  0.0221             0.0009   \n",
       "0            originality  0.9621  0.1237  0.1009  0.0409             0.0010   \n",
       "2                gptzero  0.6637  0.3091  0.0062  0.6662             0.1628   \n",
       "3  roberta-base-detector  0.5364  0.0077  0.4091  0.5035             0.9998   \n",
       "\n",
       "           model  \n",
       "1  Claude Opus 4  \n",
       "0  Claude Opus 4  \n",
       "2  Claude Opus 4  \n",
       "3  Claude Opus 4  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['model'] = \"Claude Opus 4\"\n",
    "summary_df_claude_opus_4 = summary_df.copy()\n",
    "summary_df_claude_opus_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>Claude Sonnet 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Claude Sonnet 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>Claude Sonnet 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>Claude Sonnet 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                detector   AUROC  Δ-Mean     FPR     FNR  Optimal Threshold  \\\n",
       "1                pengram  0.9993  0.9364  0.0090  0.0136             0.0007   \n",
       "0            originality  0.9573  0.1241  0.1114  0.0510             0.0009   \n",
       "2                gptzero  0.7017  0.3840  0.0063  0.5900             0.0526   \n",
       "3  roberta-base-detector  0.5179  0.0020  0.4070  0.5422             0.9998   \n",
       "\n",
       "             model  \n",
       "1  Claude Sonnet 4  \n",
       "0  Claude Sonnet 4  \n",
       "2  Claude Sonnet 4  \n",
       "3  Claude Sonnet 4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['model'] = \"Claude Sonnet 4\"\n",
    "summary_df_claude_sonnet_4 = summary_df.copy()\n",
    "summary_df_claude_sonnet_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>Gemini 2.0 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>originality</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>Gemini 2.0 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.5311</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>Gemini 2.0 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5289</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>Gemini 2.0 Flash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                detector   AUROC  Δ-Mean     FPR     FNR  Optimal Threshold  \\\n",
       "1                pengram  0.9981  0.9328  0.0090  0.0231             0.0008   \n",
       "0            originality  0.9674  0.1862  0.0998  0.0497             0.0010   \n",
       "2                gptzero  0.7748  0.5311  0.0061  0.4441             0.1176   \n",
       "3  roberta-base-detector  0.5289  0.0074  0.3800  0.5472             0.9998   \n",
       "\n",
       "              model  \n",
       "1  Gemini 2.0 Flash  \n",
       "0  Gemini 2.0 Flash  \n",
       "2  Gemini 2.0 Flash  \n",
       "3  Gemini 2.0 Flash  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df['model'] = \"Gemini 2.0 Flash\"\n",
    "summary_df_gemini_2_flash = summary_df.copy()\n",
    "summary_df_gemini_2_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16 entries, 1 to 3\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   detector           16 non-null     object \n",
      " 1   AUROC              16 non-null     float64\n",
      " 2   Δ-Mean             16 non-null     float64\n",
      " 3   FPR                16 non-null     float64\n",
      " 4   FNR                16 non-null     float64\n",
      " 5   Optimal Threshold  16 non-null     float64\n",
      " 6   model              16 non-null     object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 1.0+ KB\n"
     ]
    }
   ],
   "source": [
    "summary_stealth_df_final = pd.concat([summary_df_4_1, \n",
    "                              summary_df_claude_opus_4,\n",
    "                              summary_df_claude_sonnet_4,\n",
    "                              summary_df_gemini_2_flash], \n",
    "                             axis = 0)\n",
    "\n",
    "summary_stealth_df_final.info()\n",
    "summary_stealth_df_final.to_csv(\"summary_stealth_df_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute AUC ROC, FPR, FNR by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- No word count filter applied. Processing all entries. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Detector</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Δ-Mean</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Optimal Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon review</td>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon review</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon review</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon review</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.9940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blog</td>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blog</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.2436</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blog</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blog</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>news</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.9539</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>news</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.4896</td>\n",
       "      <td>-0.0106</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>novel</td>\n",
       "      <td>pengram</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>novel</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>novel</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7816</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>novel</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5265</td>\n",
       "      <td>-0.0112</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>restaurant review</td>\n",
       "      <td>pengram</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>restaurant review</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>restaurant review</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>restaurant review</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.9981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resume</td>\n",
       "      <td>pengram</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resume</td>\n",
       "      <td>originality</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resume</td>\n",
       "      <td>gptzero</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.7311</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resume</td>\n",
       "      <td>roberta-base-detector</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Genre               Detector   AUROC  Δ-Mean     FPR     FNR  \\\n",
       "2       amazon review                pengram  0.9950  0.6988  0.0100  0.0500   \n",
       "1       amazon review            originality  0.8883  0.2319  0.2932  0.0625   \n",
       "0       amazon review                gptzero  0.6697  0.3283  0.0200  0.6400   \n",
       "3       amazon review  roberta-base-detector  0.5973  0.0798  0.3650  0.4300   \n",
       "6                blog                pengram  0.9988  0.8299  0.0000  0.0200   \n",
       "5                blog            originality  0.9934  0.2436  0.0493  0.0299   \n",
       "4                blog                gptzero  0.7349  0.4542  0.0050  0.5250   \n",
       "7                blog  roberta-base-detector  0.5547  0.0510  0.0750  0.8100   \n",
       "10               news                pengram  0.9982  0.9767  0.0033  0.0133   \n",
       "9                news            originality  0.9539  0.2842  0.1781  0.0441   \n",
       "8                news                gptzero  0.8183  0.6346  0.0100  0.3533   \n",
       "11               news  roberta-base-detector  0.4896 -0.0106  0.2300  0.7100   \n",
       "14              novel                pengram  1.0000  0.9999  0.0000  0.0000   \n",
       "13              novel            originality  0.9961  0.1203  0.0040  0.0366   \n",
       "12              novel                gptzero  0.7816  0.5253  0.0000  0.4369   \n",
       "15              novel  roberta-base-detector  0.5265 -0.0112  0.4620  0.4410   \n",
       "18  restaurant review                pengram  0.9980  0.6748  0.0100  0.0100   \n",
       "17  restaurant review            originality  0.9160  0.2419  0.0870  0.2073   \n",
       "16  restaurant review                gptzero  0.7149  0.4246  0.0100  0.5600   \n",
       "19  restaurant review  roberta-base-detector  0.4988  0.0208  0.4700  0.4800   \n",
       "22             resume                pengram  1.0000  0.9997  0.0000  0.0000   \n",
       "21             resume            originality  0.9741  0.0910  0.0677  0.0573   \n",
       "20             resume                gptzero  0.8724  0.7311  0.0000  0.2552   \n",
       "23             resume  roberta-base-detector  0.5677  0.0051  0.5573  0.2448   \n",
       "\n",
       "    Optimal Threshold  \n",
       "2              0.0001  \n",
       "1              0.0009  \n",
       "0              0.2000  \n",
       "3              0.9940  \n",
       "6              0.0001  \n",
       "5              0.0007  \n",
       "4              0.2941  \n",
       "7              0.9998  \n",
       "10             0.1987  \n",
       "9              0.0012  \n",
       "8              0.6857  \n",
       "11             0.9998  \n",
       "14             0.9878  \n",
       "13             0.0010  \n",
       "12             0.1176  \n",
       "15             0.9997  \n",
       "18             0.0000  \n",
       "17             0.0025  \n",
       "16             0.5294  \n",
       "19             0.9981  \n",
       "22             0.9512  \n",
       "21             0.0010  \n",
       "20             0.3750  \n",
       "23             0.9997  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 1A – AUROC, Δ-Mean, FPR & FNR by Genre\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Set to True to filter by word count, or False to process the entire file.\n",
    "APPLY_WORD_COUNT_FILTER = False \n",
    "\n",
    "# Define the filtering criteria (only used if the filter is active)\n",
    "# You can choose to keep texts WITH MORE than (>=) or LESS than (<) the threshold.\n",
    "WORD_COUNT_THRESHOLD = 50\n",
    "FILTER_MODE = \"<\" # Options: \">=\" to keep long texts, \"<\" to keep short texts.\n",
    "\n",
    "# === Load JSON file ===\n",
    "input_path = '' \n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# By default, we process the whole dataset\n",
    "data_to_process = data.copy()\n",
    "\n",
    "# Conditionally apply the filter if the switch is on\n",
    "if APPLY_WORD_COUNT_FILTER:\n",
    "    print(f\"--- Applying Word Count Filter (Mode: {FILTER_MODE} {WORD_COUNT_THRESHOLD} words) ---\")\n",
    "    original_count = len(data)\n",
    "    \n",
    "    if FILTER_MODE == \">=\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) >= WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\">= {WORD_COUNT_THRESHOLD}\"\n",
    "    elif FILTER_MODE == \"<\":\n",
    "        data_to_process = [\n",
    "            item for item in data if len(item.get(\"text\", \"\").split()) < WORD_COUNT_THRESHOLD\n",
    "        ]\n",
    "        filter_desc = f\"< {WORD_COUNT_THRESHOLD}\"\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: Invalid FILTER_MODE '{FILTER_MODE}'. No filtering will be applied.\")\n",
    "        filter_desc = \"None\"\n",
    "\n",
    "    filtered_count = len(data_to_process)\n",
    "    print(f\"Filtering complete. Kept {filtered_count} of {original_count} entries (texts with {filter_desc} words).\")\n",
    "else:\n",
    "    print(\"--- No word count filter applied. Processing all entries. ---\")\n",
    "    \n",
    "# === Supported detectors and their probability fields ===\n",
    "detectors = {\n",
    "    \"originality\": lambda d: d.get(\"confidence\", {}).get(\"AI\", None),\n",
    "    \"pengram\": lambda d: d.get(\"ai_likelihood\", None),\n",
    "    \"gptzero\": lambda d: d.get(\"average_generated_prob\", None),\n",
    "    \"roberta-base-detector\": lambda d: d if isinstance(d, (float, int)) else None\n",
    "}\n",
    "\n",
    "# === Collect scores, now including genre ===\n",
    "records = []\n",
    "for entry in data_to_process:\n",
    "    # --- NEW: Extract genre for each entry ---\n",
    "    genre = entry.get(\"genre\", \"unknown\") # Default to 'unknown' if genre key is missing\n",
    "\n",
    "    # Human text\n",
    "    hv = entry.get(\"human_verdict\", {})\n",
    "    for det, extract in detectors.items():\n",
    "        if det in hv:\n",
    "            prob = extract(hv[det])\n",
    "            if prob is not None:\n",
    "                records.append({\n",
    "                    \"genre\": genre, # Add genre\n",
    "                    \"detector\": det, \n",
    "                    \"source\": \"human\", \n",
    "                    \"score\": prob, \n",
    "                    \"label\": 0\n",
    "                })\n",
    "\n",
    "    # AI-generated text from all models\n",
    "    for model, verdicts in entry.get(\"ai_verdicts\", {}).items():\n",
    "        for det, extract in detectors.items():\n",
    "            if det in verdicts:\n",
    "                prob = extract(verdicts[det])\n",
    "                if prob is not None:\n",
    "                    records.append({\n",
    "                        \"genre\": genre, # Add genre\n",
    "                        \"detector\": det, \n",
    "                        \"source\": f\"ai_{model}\", \n",
    "                        \"score\": prob, \n",
    "                        \"label\": 1\n",
    "                    })\n",
    "\n",
    "# === Convert to DataFrame ===\n",
    "df = pd.DataFrame(records)\n",
    "if df.empty:\n",
    "    print(\"⚠️ No records were created. Please check your input JSON structure and detectors.\")\n",
    "    exit()\n",
    "\n",
    "# === Compute metrics for each Genre-Detector combination ===\n",
    "summary = []\n",
    "\n",
    "# --- NEW: Group by both genre and detector ---\n",
    "for (genre, detector), group in df.groupby([\"genre\", \"detector\"]):\n",
    "    \n",
    "    # Ensure there are both human and AI scores to process in the group\n",
    "    if not (0 in group[\"label\"].values and 1 in group[\"label\"].values):\n",
    "        print(f\"Skipping group ('{genre}', '{detector}') as it's missing either human or AI scores.\")\n",
    "        continue\n",
    "\n",
    "    ai_scores = group[group[\"label\"] == 1][\"score\"]\n",
    "    human_scores = group[group[\"label\"] == 0][\"score\"]\n",
    "    all_labels = group[\"label\"]\n",
    "    all_scores = group[\"score\"]\n",
    "\n",
    "    # --- Calculate AUROC and Δ-Mean ---\n",
    "    try:\n",
    "        auroc = roc_auc_score(all_labels, all_scores)\n",
    "    except ValueError:\n",
    "        auroc = None\n",
    "\n",
    "    delta_mean = ai_scores.mean() - human_scores.mean()\n",
    "\n",
    "    # --- Calculate FPR and FNR at an optimal threshold ---\n",
    "    fpr_values, tpr_values, thresholds = roc_curve(all_labels, all_scores)\n",
    "    j_statistic = tpr_values - fpr_values\n",
    "    optimal_idx = np.argmax(j_statistic)\n",
    "    \n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_fpr = fpr_values[optimal_idx]\n",
    "    optimal_tpr = tpr_values[optimal_idx]\n",
    "    optimal_fnr = 1 - optimal_tpr\n",
    "\n",
    "    summary.append({\n",
    "        \"Genre\": genre, # Add genre to the final summary\n",
    "        \"Detector\": detector,\n",
    "        \"AUROC\": round(auroc, 4) if auroc is not None else \"N/A\",\n",
    "        \"Δ-Mean\": round(delta_mean, 4),\n",
    "        \"FPR\": round(optimal_fpr, 4),\n",
    "        \"FNR\": round(optimal_fnr, 4),\n",
    "        \"Optimal Threshold\": round(optimal_threshold, 4)\n",
    "    })\n",
    "\n",
    "# === Final Table 1A Output ===\n",
    "summary_df = pd.DataFrame(summary)\n",
    "if not summary_df.empty:\n",
    "    # Sort by Genre first, then by AUROC within each genre\n",
    "    summary_df = summary_df.sort_values(by=[\"Genre\", \"AUROC\"], ascending=[True, False])\n",
    "\n",
    "# Display the final DataFrame\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df['model'] = \"GPT-4.1\"\n",
    "summary_df_4_1 = summary_df.copy()\n",
    "# summary_df_4_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df['model'] = \"Claude Opus 4\"\n",
    "summary_df_claude_opus_4 = summary_df.copy()\n",
    "# summary_df_claude_opus_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df['model'] = \"Claude Sonnet 4\"\n",
    "summary_df_claude_sonnet_4 = summary_df.copy()\n",
    "# summary_df_claude_sonnet_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df['model'] = \"Gemini 2.0 Flash\"\n",
    "summary_df_gemini_2_flash = summary_df.copy()\n",
    "# summary_df_gemini_2_flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 96 entries, 2 to 23\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Genre              96 non-null     object \n",
      " 1   Detector           96 non-null     object \n",
      " 2   AUROC              96 non-null     float64\n",
      " 3   Δ-Mean             96 non-null     float64\n",
      " 4   FPR                96 non-null     float64\n",
      " 5   FNR                96 non-null     float64\n",
      " 6   Optimal Threshold  96 non-null     float64\n",
      " 7   model              96 non-null     object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "summary_stealth_genre__df_final = pd.concat([summary_df_4_1, \n",
    "                              summary_df_claude_opus_4,\n",
    "                              summary_df_claude_sonnet_4,\n",
    "                              summary_df_gemini_2_flash], \n",
    "                             axis = 0)\n",
    "\n",
    "summary_stealth_genre__df_final.info()\n",
    "summary_stealth_genre__df_final.to_csv(\"summary_stealth_genre_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDXRDZuU57ZJmFKqq5uJOY",
   "mount_file_id": "1YWrGKSRraQnGxvSYSJJlRPKtYBH04r-i",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
